---
title: "Spatial machine learning with the tidymodels framework"
author:
  - name: Hanna Meyer
    orcid:  0000-0003-0556-0210
  - name: Jakub Nowosad
    url: https://jakubnowosad.com
    orcid:  0000-0002-1057-3721
date: ""
slug: sml-bp3
categories:
  - rstats
  - sml
tags: [caret, CAST, mlr3, tidymodels, machine-learning, spatial-machine-learning]
draft: true
mermaid-format: png
knitr:
  opts_chunk:
    message: false
---

::: {.callout-note appearance="simple"}

This is the third part of a blog post series on spatial machine learning with R.

You can find the list of other blog posts in this series [in part one](post/2025/sml-bp1/).

:::

## Introduction

In this blog post, we will show how to use the **tidymodels** framework for spatial machine learning.
The **tidymodels** framework is a collection of R packages for modeling and machine learning using *tidyverse* principles.

## Prepare data

Load the required packages:

```{r}
#| results: hide
#| message: false
library(terra)
library(sf)
library(tidymodels)
library(ranger)
library(dplyr)
library(spatialsample)
library(waywiser)
library(vip)
```

Read data:

```{r}
#| results: hide
#| message: false
trainingdata <- sf::st_read("https://github.com/LOEK-RS/FOSSGIS2025-examples/raw/refs/heads/main/data/temp_train.gpkg")
predictors <- terra::rast("https://github.com/LOEK-RS/FOSSGIS2025-examples/raw/refs/heads/main/data/predictors.tif")
```

Prepare data by extracting the training data from the raster and converting it to a `sf` object.

```{r}
#| results: hide
#| message: false
trainDat <- sf::st_as_sf(terra::extract(predictors, trainingdata, bind = TRUE))
predictor_names <- names(predictors) # Extract predictor names from the raster
response_name <- "temp"
```

::: callout-note
Compared to **caret**, no dropping of the geometries is required.
:::

## A simple model training and prediction

First, we train a random forest model.
This is done by defining a recipe and a model, and then combining them into a workflow.
Such a workflow can then be used to fit the model to the data.

```{r}
# Define the recipe
formula <- as.formula(paste(
    response_name,
    "~",
    paste(predictor_names, collapse = " + ")
))
recipe <- recipes::recipe(formula, data = trainDat)

rf_model <- parsnip::rand_forest(trees = 100, mode = "regression") |>
    set_engine("ranger", importance = "impurity")

# Create the workflow
workflow <- workflows::workflow() |>
    workflows::add_recipe(recipe) |>
    workflows::add_model(rf_model)

# Fit the model
rf_fit <- parsnip::fit(workflow, data = trainDat)
```

Now, let's use the model for spatial prediction with `terra::predict()`.

```{r}
prediction_raster <- terra::predict(predictors, rf_fit, na.rm = TRUE)
plot(prediction_raster)
```

## Spatial cross-validation

Cross-validation requires to specify how the data is split into folds.
Here, we define a non-spatial cross-validation with `rsample::vfold_cv()` and a spatial cross-validation with `spatialsample::spatial_block_cv()`.

```{r}
random_folds <- rsample::vfold_cv(trainDat, v = 4)
block_folds <- spatialsample::spatial_block_cv(trainDat, v = 4, n = 2)
spatialsample::autoplot(block_folds)

# control cross-validation
keep_pred <- tune::control_resamples(save_pred = TRUE, save_workflow = TRUE)
```

Next, we fit the model to the data using cross-validation with `tune::fit_resamples()`.

```{r}
### Cross-validation
rf_random <- tune::fit_resamples(
    workflow,
    resamples = random_folds,
    control = keep_pred
)
rf_spatial <- tune::fit_resamples(
    workflow,
    resamples = block_folds,
    control = keep_pred
)
```

To compare the fitted models, we can use the `tune::collect_metrics()` function to get the metrics.

```{r}
### get CV metrics
tune::collect_metrics(rf_random)
tune::collect_metrics(rf_spatial)
# rf_spatial$.metrics # metrics from each fold
```

Additionally, we can visualize the models by extracting their predictions with `tune::collect_predictions()` and plotting them.

```{r}
#| echo: false
### analyze CV predictions
rf_spatial_pred <- data.frame(
    tune::collect_predictions(rf_spatial),
    type = "spatial"
)
rf_random_pred <- data.frame(
    tune::collect_predictions(rf_random),
    type = "random"
)
pred_cv <- rbind(rf_spatial_pred, rf_random_pred)
pred_cv |>
    ggplot(aes(x = temp, y = .pred)) +
    geom_point(alpha = .15) +
    geom_abline(color = "red") +
    coord_obs_pred() +
    facet_wrap("type") +
    ylab("Predicted")
```

::: callout-note
Similar to **caret**, we first define folds and a definition of train control. 
The final model, however, is still stored in a separate object.
:::

## Model tuning: spatial hyperparameter tuning and variable selection

### Hyperparameter tuning

Next, we tune the model hyperparameters.
For this, we change the workflow to include the tuning specifications by using the `tune()` function inside the model definition and define a grid of hyperparameters to search over.
The tuning is done with `tune::tune_grid()`.

```{r}
# mark two parameters for tuning:
rf_model <- parsnip::rand_forest(
    trees = 100,
    mode = "regression",
    mtry = tune(),
    min_n = tune()
) |>
    set_engine("ranger", importance = "impurity")

workflow <- update_model(workflow, rf_model)

# define tune grid:
grid_rf <-
    grid_space_filling(
        mtry(range = c(1, 20)),
        min_n(range = c(2, 10)),
        size = 30
    )

# tune:
rf_tuning <- tune_grid(
    workflow,
    resamples = block_folds,
    grid = grid_rf,
    control = keep_pred
)
```

The results can be extracted with `collect_metrics()` and then visualized.

```{r}
rf_tuning |>
    collect_metrics()

rf_tuning |>
    collect_metrics() |>
    mutate(min_n = factor(min_n)) |>
    ggplot(aes(mtry, mean, color = min_n)) +
    geom_line(linewidth = 1.5, alpha = 0.6) +
    geom_point(size = 2) +
    facet_wrap(~.metric, scales = "free", nrow = 2) +
    scale_x_log10(labels = scales::label_number()) +
    scale_color_viridis_d(option = "plasma", begin = .9, end = 0)
```

Finally, we can extract the best model and use it to get the variable importance and make predictions.

```{r}
finalmodel <- fit_best(rf_tuning)
finalmodel

imp <- extract_fit_parsnip(finalmodel) |>
    vip::vip()
imp

final_pred <- terra::predict(predictors, finalmodel, na.rm = TRUE)
plot(final_pred)
```

## Area of applicability

The **waywiser** package provides a set of tools for assessing spatial models, including an implementation of multi-scale assessment and area of applicability.
The area of applicability is a measure of how well the model (given the training data) can be applied to the prediction data.
It can be calculated with the `ww_area_of_applicability()` function, and then predicted on the raster with `terra::predict()`.

```{r}
model_aoa <- waywiser::ww_area_of_applicability(
    st_drop_geometry(trainDat[, predictor_names]),
    importance = vip::vi_model(finalmodel)
)
AOA <- terra::predict(predictors, model_aoa)
plot(AOA$aoa)
```

More information on the **waywiser** package can be found in its [documentation](https://docs.ropensci.org/waywiser/).

## Summary

This blog post showed how to use the **tidymodels** framework for spatial machine learning.
We demonstrated how to train a random forest model, perform spatial cross-validation, tune hyperparameters, and assess the area of applicability.
We also showed how to visualize the results and extract variable importance.^[We have not, though, covered all the features of the **tidymodels** framework, such as feature selection (<https://stevenpawley.github.io/recipeselectors/>) or model ensembling.]

The **tidymodels** framework with its packages **spatialsample** and **waywiser** provides a powerful and flexible way to perform spatial machine learning in R.
At the same time, it is a bit more complex than **caret**: it requires getting familiar with several packages^[Including remembering their names and roles] and relationships between them. 
Thus, the decision of which framework to use depends on the specific needs and preferences of the user.

::: {.callout-note appearance="simple"}

This blog post was originally written as a supplement to the poster "An Inventory of Spatial Machine Learning Packages in R" presented at the FOSSGIS 2025 conference in Muenster, Germany.
The poster is available at <https://doi.org/10.5281/zenodo.15088973>.

:::