{
  "hash": "f4f198f0427342fc5ab1c008871f14bb",
  "result": {
    "engine": "knitr",
    "markdown": "---\ntitle: \"Spatial machine learning with the tidymodels framework\"\nauthor:\n  - name: Hanna Meyer\n    orcid:  0000-0003-0556-0210\n  - name: Jakub Nowosad\n    url: https://jakubnowosad.com\n    orcid:  0000-0002-1057-3721\ndate: \"2025-05-28\"\nslug: sml-bp3\ncategories:\n  - rstats\n  - sml\ntags: [tidymodels, machine-learning, spatial-machine-learning]\ndraft: false\nmermaid-format: png\nknitr:\n  opts_chunk:\n    message: false\n---\n\n\n\n::: {.callout-note appearance=\"simple\"}\n\nThis is the third part of a blog post series on spatial machine learning with R.\n\nYou can find the list of other blog posts in this series [in part one](/post/2025/sml-bp1/).\n\n:::\n\n## Introduction\n\nIn this blog post, we will show how to use the **tidymodels** framework for spatial machine learning.\nThe **tidymodels** framework is a collection of R packages for modeling and machine learning using *tidyverse* principles.\n\n## Prepare data\n\nLoad the required packages:\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(terra)\nlibrary(sf)\nlibrary(tidymodels)\nlibrary(ranger)\nlibrary(dplyr)\nlibrary(spatialsample)\nlibrary(waywiser)\nlibrary(vip)\n```\n:::\n\n\n\nRead data:\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ntrainingdata <- sf::st_read(\"https://github.com/LOEK-RS/FOSSGIS2025-examples/raw/refs/heads/main/data/temp_train.gpkg\")\npredictors <- terra::rast(\"https://github.com/LOEK-RS/FOSSGIS2025-examples/raw/refs/heads/main/data/predictors.tif\")\n```\n:::\n\n\n\nPrepare data by extracting the training data from the raster and converting it to a `sf` object.\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ntrainDat <- sf::st_as_sf(terra::extract(predictors, trainingdata, bind = TRUE))\npredictor_names <- names(predictors) # Extract predictor names from the raster\nresponse_name <- \"temp\"\n```\n:::\n\n\n\n::: callout-note\nCompared to **caret**, no dropping of the geometries is required.\n:::\n\n## A simple model training and prediction\n\nFirst, we train a random forest model.\nThis is done by defining a recipe and a model, and then combining them into a workflow.\nSuch a workflow can then be used to fit the model to the data.\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Define the recipe\nformula <- as.formula(paste(\n    response_name,\n    \"~\",\n    paste(predictor_names, collapse = \" + \")\n))\nrecipe <- recipes::recipe(formula, data = trainDat)\n\nrf_model <- parsnip::rand_forest(trees = 100, mode = \"regression\") |>\n    set_engine(\"ranger\", importance = \"impurity\")\n\n# Create the workflow\nworkflow <- workflows::workflow() |>\n    workflows::add_recipe(recipe) |>\n    workflows::add_model(rf_model)\n\n# Fit the model\nrf_fit <- parsnip::fit(workflow, data = trainDat)\n```\n:::\n\n\n\nNow, let's use the model for spatial prediction with `terra::predict()`.\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nprediction_raster <- terra::predict(predictors, rf_fit, na.rm = TRUE)\nplot(prediction_raster)\n```\n\n::: {.cell-output-display}\n![](index_files/figure-html/unnamed-chunk-5-1.png){width=672}\n:::\n:::\n\n\n\n## Spatial cross-validation\n\nCross-validation requires to specify how the data is split into folds.\nHere, we define a non-spatial cross-validation with `rsample::vfold_cv()` and a spatial cross-validation with `spatialsample::spatial_block_cv()`.\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nrandom_folds <- rsample::vfold_cv(trainDat, v = 4)\nblock_folds <- spatialsample::spatial_block_cv(trainDat, v = 4, n = 2)\nspatialsample::autoplot(block_folds)\n```\n\n::: {.cell-output-display}\n![](index_files/figure-html/unnamed-chunk-6-1.png){width=672}\n:::\n\n```{.r .cell-code}\n# control cross-validation\nkeep_pred <- tune::control_resamples(save_pred = TRUE, save_workflow = TRUE)\n```\n:::\n\n\n\nNext, we fit the model to the data using cross-validation with `tune::fit_resamples()`.\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n### Cross-validation\nrf_random <- tune::fit_resamples(\n    workflow,\n    resamples = random_folds,\n    control = keep_pred\n)\nrf_spatial <- tune::fit_resamples(\n    workflow,\n    resamples = block_folds,\n    control = keep_pred\n)\n```\n:::\n\n\n\nTo compare the fitted models, we can use the `tune::collect_metrics()` function to get the metrics.\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n### get CV metrics\ntune::collect_metrics(rf_random)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 2 × 6\n  .metric .estimator  mean     n std_err .config             \n  <chr>   <chr>      <dbl> <int>   <dbl> <chr>               \n1 rmse    standard   0.944     4  0.0923 Preprocessor1_Model1\n2 rsq     standard   0.903     4  0.0192 Preprocessor1_Model1\n```\n\n\n:::\n\n```{.r .cell-code}\ntune::collect_metrics(rf_spatial)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 2 × 6\n  .metric .estimator  mean     n std_err .config             \n  <chr>   <chr>      <dbl> <int>   <dbl> <chr>               \n1 rmse    standard   1.41      4  0.292  Preprocessor1_Model1\n2 rsq     standard   0.719     4  0.0744 Preprocessor1_Model1\n```\n\n\n:::\n\n```{.r .cell-code}\n# rf_spatial$.metrics # metrics from each fold\n```\n:::\n\n\n\nAdditionally, we can visualize the models by extracting their predictions with `tune::collect_predictions()` and plotting them.\n\n\n\n::: {.cell}\n::: {.cell-output-display}\n![](index_files/figure-html/unnamed-chunk-9-1.png){width=672}\n:::\n:::\n\n\n\n::: callout-note\nSimilar to **caret**, we first define folds and a definition of train control. \nThe final model, however, is still stored in a separate object.\n:::\n\n## Model tuning: spatial hyperparameter tuning and variable selection\n\n### Hyperparameter tuning\n\nNext, we tune the model hyperparameters.\nFor this, we change the workflow to include the tuning specifications by using the `tune()` function inside the model definition and define a grid of hyperparameters to search over.\nThe tuning is done with `tune::tune_grid()`.\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# mark two parameters for tuning:\nrf_model <- parsnip::rand_forest(\n    trees = 100,\n    mode = \"regression\",\n    mtry = tune(),\n    min_n = tune()\n) |>\n    set_engine(\"ranger\", importance = \"impurity\")\n\nworkflow <- update_model(workflow, rf_model)\n\n# define tune grid:\ngrid_rf <-\n    grid_space_filling(\n        mtry(range = c(1, 20)),\n        min_n(range = c(2, 10)),\n        size = 30\n    )\n\n# tune:\nrf_tuning <- tune_grid(\n    workflow,\n    resamples = block_folds,\n    grid = grid_rf,\n    control = keep_pred\n)\n```\n:::\n\n\n\nThe results can be extracted with `collect_metrics()` and then visualized.\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nrf_tuning |>\n    collect_metrics()\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 60 × 8\n    mtry min_n .metric .estimator  mean     n std_err .config              \n   <int> <int> <chr>   <chr>      <dbl> <int>   <dbl> <chr>                \n 1     1     5 rmse    standard   1.87      4  0.297  Preprocessor1_Model01\n 2     1     5 rsq     standard   0.611     4  0.0806 Preprocessor1_Model01\n 3     1     9 rmse    standard   1.91      4  0.257  Preprocessor1_Model02\n 4     1     9 rsq     standard   0.594     4  0.0930 Preprocessor1_Model02\n 5     2     4 rmse    standard   1.62      4  0.315  Preprocessor1_Model03\n 6     2     4 rsq     standard   0.662     4  0.0924 Preprocessor1_Model03\n 7     2     2 rmse    standard   1.52      4  0.263  Preprocessor1_Model04\n 8     2     2 rsq     standard   0.712     4  0.0795 Preprocessor1_Model04\n 9     3     7 rmse    standard   1.48      4  0.292  Preprocessor1_Model05\n10     3     7 rsq     standard   0.702     4  0.0747 Preprocessor1_Model05\n# ℹ 50 more rows\n```\n\n\n:::\n\n```{.r .cell-code}\nrf_tuning |>\n    collect_metrics() |>\n    mutate(min_n = factor(min_n)) |>\n    ggplot(aes(mtry, mean, color = min_n)) +\n    geom_line(linewidth = 1.5, alpha = 0.6) +\n    geom_point(size = 2) +\n    facet_wrap(~.metric, scales = \"free\", nrow = 2) +\n    scale_x_log10(labels = scales::label_number()) +\n    scale_color_viridis_d(option = \"plasma\", begin = .9, end = 0)\n```\n\n::: {.cell-output-display}\n![](index_files/figure-html/unnamed-chunk-11-1.png){width=672}\n:::\n:::\n\n\n\nFinally, we can extract the best model and use it to get the variable importance and make predictions.\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nfinalmodel <- fit_best(rf_tuning)\nfinalmodel\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n══ Workflow [trained] ══════════════════════════════════════════════════════════\nPreprocessor: Recipe\nModel: rand_forest()\n\n── Preprocessor ────────────────────────────────────────────────────────────────\n0 Recipe Steps\n\n── Model ───────────────────────────────────────────────────────────────────────\nRanger result\n\nCall:\n ranger::ranger(x = maybe_data_frame(x), y = y, mtry = min_cols(~15L,      x), num.trees = ~100, min.node.size = min_rows(~7L, x), importance = ~\"impurity\",      num.threads = 1, verbose = FALSE, seed = sample.int(10^5,          1)) \n\nType:                             Regression \nNumber of trees:                  100 \nSample size:                      195 \nNumber of independent variables:  22 \nMtry:                             15 \nTarget node size:                 7 \nVariable importance mode:         impurity \nSplitrule:                        variance \nOOB prediction error (MSE):       0.7108042 \nR squared (OOB):                  0.9108492 \n```\n\n\n:::\n\n```{.r .cell-code}\nimp <- extract_fit_parsnip(finalmodel) |>\n    vip::vip()\nimp\n```\n\n::: {.cell-output-display}\n![](index_files/figure-html/unnamed-chunk-12-1.png){width=672}\n:::\n\n```{.r .cell-code}\nfinal_pred <- terra::predict(predictors, finalmodel, na.rm = TRUE)\nplot(final_pred)\n```\n\n::: {.cell-output-display}\n![](index_files/figure-html/unnamed-chunk-12-2.png){width=672}\n:::\n:::\n\n\n\n## Area of applicability\n\nThe **waywiser** package provides a set of tools for assessing spatial models, including an implementation of multi-scale assessment and area of applicability.\nThe area of applicability is a measure of how well the model (given the training data) can be applied to the prediction data.\nIt can be calculated with the `ww_area_of_applicability()` function, and then predicted on the raster with `terra::predict()`.\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nmodel_aoa <- waywiser::ww_area_of_applicability(\n    st_drop_geometry(trainDat[, predictor_names]),\n    importance = vip::vi_model(finalmodel)\n)\nAOA <- terra::predict(predictors, model_aoa)\nplot(AOA$aoa)\n```\n\n::: {.cell-output-display}\n![](index_files/figure-html/unnamed-chunk-13-1.png){width=672}\n:::\n:::\n\n\n\nMore information on the **waywiser** package can be found in its [documentation](https://docs.ropensci.org/waywiser/).\n\n## Summary\n\nThis blog post showed how to use the **tidymodels** framework for spatial machine learning.\nWe demonstrated how to train a random forest model, perform spatial cross-validation, tune hyperparameters, and assess the area of applicability.\nWe also showed how to visualize the results and extract variable importance.^[We have not, though, covered all the features of the **tidymodels** framework, such as feature selection (<https://stevenpawley.github.io/recipeselectors/>) or model ensembling.]\n\nThe **tidymodels** framework with its packages **spatialsample** and **waywiser** provides a powerful and flexible way to perform spatial machine learning in R.\nAt the same time, it is a bit more complex than **caret**: it requires getting familiar with several packages^[Including remembering their names and roles] and relationships between them. \nThus, the decision of which framework to use depends on the specific needs and preferences of the user.\n\n::: {.callout-note appearance=\"simple\"}\n\nThis blog post was originally written as a supplement to the poster \"An Inventory of Spatial Machine Learning Packages in R\" presented at the FOSSGIS 2025 conference in Muenster, Germany.\nThe poster is available at <https://doi.org/10.5281/zenodo.15088973>.\n\n:::",
    "supporting": [
      "index_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}