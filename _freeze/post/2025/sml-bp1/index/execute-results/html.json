{
  "hash": "636995e99691ecc95926e4b99fce20e0",
  "result": {
    "engine": "knitr",
    "markdown": "---\ntitle: \"Spatial machine learning with R: caret, tidymodels, and mlr3\"\nauthor:\n    - name: Jakub Nowosad\n      url: https://jakubnowosad.com\n      orcid:  0000-0002-1057-3721\ndate: \"2025-04-30\"\nslug: sml-bp1\ncategories:\n    - rstats\n    - sml\ntags: [caret, CAST, mlr3, tidymodels, machine-learning, spatial-machine-learning]\ndraft: false\nmermaid-format: png\nknitr:\n    opts_chunk:\n        message: false\n---\n\n\n\n\n::: {.callout-note appearance=\"simple\"}\n\nThis is the first part of a blog post series on spatial machine learning with R.\n\n- [Part 2](/post/2025/sml-bp2/): Spatial machine learning with caret\n- [Part 3](/post/2025/sml-bp3/): Spatial machine learning with the tidymodels framework\n- [Part 4](/post/2025/sml-bp4/): Spatial machine learning with mlr3\n- [Part 5](/post/2025/sml-bp5/): Specialized R packages for spatial machine learning: An introduction to RandomForestsGLS, spatialRF, and meteo\n- [Part 6](/post/2025/sml-bp6/): Specialized R packages for spatial cross-validation: sperrorest and blockCV\n\n:::\n\nThe R language has a variety of packages for machine learning, and many of them can be used for machine learning tasks in a spatial context (*spatial machine learning*).\nSpatial machine learning is generally different from traditional machine learning, as variables located closer to each other are often more similar than those located further apart.\nThus, we need to consider that when building machine learning models.\n\nIn this blog post, we compare three of the most popular machine learning frameworks in R: **caret**, **tidymodels**, and **mlr3**.\nWe use a simple example to demonstrate how to use these frameworks for a spatial machine learning task and how their workflows differ.\nThe goal here is to provide a general sense of how the spatial machine learning workflow looks like, and how different frameworks can be used to achieve the same goal.\n\n<!-- \n\n\n\n\n```{mermaid}\n%%| fig-width: 8\n%%| fig-height: 6.5\n%%| echo: false\n%%| eval: false\n%%| fig-cap: \"A possible workflow of the spatial machine learning task.\"\nflowchart TB\n    A[Data] --> B(Model specification)\n    B --> C(Resampling #1)\n    B --> D(Resampling #2)\n    B --> E(Resampling #...)\n    B --> F(Resampling #N)\n    C --> G(Evaluation)\n    D --> G\n    E --> G\n    F --> G\n    G --> H[Prediction]\n    H --> I[Area of applicability]\n```\n\n\n\n\n-->\n\n![A possible workflow of the spatial machine learning task.](mermaid-figure-1.png)\n\n# Inputs\n\nOur task is to predict the temperature in Spain using a set of covariates. \nWe have two datasets for that purpose: the first one, `temperature_train`, contains the temperature measurements from 195 locations in Spain, and the second one, `predictor_stack`, contains the covariates we will use to predict the temperature.^[Source of the data: Milà et al. (2024), https://doi.org/10.5194/gmd-17-6007-2024]\nThese covariates include variables such as population density (`popdens`), distance to the coast (`coast`), and elevation (`elev`), among others.\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(terra)\nlibrary(sf)\ntrain_points <- sf::read_sf(\"https://github.com/LOEK-RS/FOSSGIS2025-examples/raw/refs/heads/main/data/temp_train.gpkg\")\npredictor_stack <- terra::rast(\"https://github.com/LOEK-RS/FOSSGIS2025-examples/raw/refs/heads/main/data/predictors.tif\")\n```\n:::\n\n\n\n\nWe use a subset of fourteen of the available covariates to predict the temperature.\nBut before doing that, to prepare our data for modeling, we need to extract the covariate values at the locations of our training points.\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\npredictor_names <- names(predictor_stack)[1:14]\ntemperature_train <- terra::extract(predictor_stack[[predictor_names]],\n    train_points,\n    bind = TRUE\n) |>\n    sf::st_as_sf()\n```\n:::\n\n\n\n\nNow, our `temperature_train` dataset contains the temperature measurements and the covariate values at each location and is ready for modeling.\n\n# Loading packages\n\nUsing each of the frameworks requires loading the respective packages.\n\n::: {.panel-tabset group=\"language\"}\n\n## caret\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(caret) # for modeling\nlibrary(blockCV) # for spatial cross-validation\nlibrary(CAST) # for area of applicability\n```\n:::\n\n\n\n\n## tidymodels\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(tidymodels) # metapackage for modeling\nlibrary(spatialsample) # for spatial cross-validation\nlibrary(waywiser) # for area of applicability\nlibrary(vip) # for variable importance (used in AOA)\n```\n:::\n\n\n\n\n## mlr3\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(mlr3verse) # metapackage for mlr3 modeling\nlibrary(mlr3spatiotempcv) # for spatial cross-validation\nlibrary(CAST) # for area of applicability\nlgr::get_logger(\"mlr3\")$set_threshold(\"warn\")\n```\n:::\n\n\n\n\n:::\n\n# Model specification\n\nEach of the frameworks has its own way of setting up the modeling workflow.\nThis may include defining the model, the resampling method, and the hyperparameter values^[Or the hyperparameter tuning grid, in a more advanced scenario.].\nIn this example, we use random forest models as implemented in the **ranger** package with the following hyperparameters:\n\n- `mtry`: the number of variables randomly sampled as candidates at each split of 8\n- `splitrule`: the splitting rule of `\"extratrees\"`\n- `min.node.size`: the minimum size of terminal nodes of 5\n\nWe also use a spatial cross-validation method with 5 folds.\nIt means that the data is divided into many spatial blocks, and each block is assigned to a fold.\nThe model is trained on a set of blocks belonging to the training set and evaluated on the remaining blocks.\nNote that each framework has its own way of defining the resampling method, and thus, the implementation and the folds may differ slightly.\n\n::: {.panel-tabset group=\"language\"}\n\n## caret\n\nFor **caret**, we define the hyperparameter grid using the `expand.grid()` function, and the resampling method using the `trainControl()` function.\nIn this case, to use spatial cross-validation, we use the `blockCV` package to create the folds, and then pass them to the `trainControl()` function.\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nset.seed(22)\n# hyperparameters\ntn_grid <- expand.grid(\n    mtry = 8,\n    splitrule = \"extratrees\",\n    min.node.size = 5\n)\n\n# resampling\nspatial_blocks <- blockCV::cv_spatial(\n    temperature_train,\n    k = 5,\n    hexagon = FALSE,\n    progress = FALSE\n)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\n  train test\n1   155   40\n2   160   35\n3   155   40\n4   154   41\n5   156   39\n```\n\n\n:::\n\n::: {.cell-output-display}\n![](index_files/figure-html/index-7-1.png){width=672}\n:::\n\n```{.r .cell-code}\ntrain_ids <- lapply(spatial_blocks$folds_list, function(x) x[[1]])\ntest_ids <- lapply(spatial_blocks$folds_list, function(x) x[[2]])\n\ntr_control <- caret::trainControl(\n    method = \"cv\",\n    index = train_ids,\n    indexOut = test_ids,\n    savePredictions = TRUE\n)\n```\n:::\n\n\n\n\n## tidymodels\n\nIn **tidymodels**, the steps are to:\n\n1. Specify the modeling formula using the `recipe()` function.\n2. Define the model using a function from the **parsnip** package, including the hyperparameters.\n3. Create a workflow using the `workflow()` function, which combines the recipe and the model.\n4. Define the resampling method using the `spatial_block_cv()` function from the **spatialsample** package.\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nset.seed(22)\nform <- as.formula(paste0(\"temp ~ \", paste(predictor_names, collapse = \" + \")))\nrecipe <- recipes::recipe(form, data = temperature_train)\n\nrf_model <- parsnip::rand_forest(\n    trees = 100,\n    mtry = 8,\n    min_n = 5,\n    mode = \"regression\"\n) |>\n    set_engine(\"ranger\", splitrule = \"extratrees\", importance = \"impurity\")\n\nworkflow <- workflows::workflow() |>\n    workflows::add_recipe(recipe) |>\n    workflows::add_model(rf_model)\n\nblock_folds <- spatialsample::spatial_block_cv(temperature_train, v = 5)\nspatialsample::autoplot(block_folds)\n```\n\n::: {.cell-output-display}\n![](index_files/figure-html/index-8-1.png){width=672}\n:::\n:::\n\n\n\n\n## mlr3\n\nThe basic **mlr3** steps are connected to its terminology:\n\n1. **Task**: define the task using the `as_task_regr_st()` function, which specifies the target variable and the data.\n2. **Learner**: define the model using the `lrn()` function, which specifies the model type and the hyperparameters.\n3. **Resampling**: define the resampling method using the `rsmp()` function, which specifies the type of resampling and the number of folds.\nHere, we use the `spcv_block` resampling method.\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nset.seed(22)\ntask <- mlr3spatiotempcv::as_task_regr_st(temperature_train, target = \"temp\")\nlearner <- mlr3::lrn(\"regr.ranger\",\n    num.trees = 100,\n    importance = \"impurity\",\n    mtry = 8,\n    min.node.size = 5,\n    splitrule = \"extratrees\"\n)\nresampling <- mlr3::rsmp(\"spcv_block\",\n    folds = 5,\n    cols = 10, rows = 10\n)\n```\n:::\n\n\n\n\n:::\n\n# Modeling\n\n::: {.panel-tabset group=\"language\"}\n\n## caret\n\nThe main function of the **caret** package is `train()`, which takes the formula, the data, the model type, the tuning grid, the training control (including the resampling method), and some other arguments (e.g., the number of trees).\nThe `train()` function will automatically perform the resampling and hyperparameter tuning (if applicable).\nThe final model is stored in the `finalModel` object.\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nmodel_caret <- caret::train(\n    temp ~ .,\n    data = st_drop_geometry(temperature_train),\n    method = \"ranger\",\n    tuneGrid = tn_grid,\n    trControl = tr_control,\n    num.trees = 100,\n    importance = \"impurity\"\n)\nmodel_caret_final <- model_caret$finalModel\n```\n:::\n\n\n\n\n## tidymodels\n\nIn **tidymodels**, the `fit_resamples()` function takes the previously defined workflow and the resampling folds.\nHere, we also use the `control` argument to save the predictions and the workflow, which can be useful for later analysis.\nThe `fit_best()` function is used to fit the best model based on the resampling results.\n    \n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nrf_spatial <- tune::fit_resamples(\n    workflow,\n    resamples = block_folds,\n    control = tune::control_resamples(save_pred = TRUE, save_workflow = TRUE)\n)\nmodel_tidymodels <- fit_best(rf_spatial)\n```\n:::\n\n\n\n\n## mlr3\n\nThe **mlr3** workflow applies the `resample()` function to the task, the learner, and the resampling method.\nThen, to get the final model, we use the `train()` function on previously defined task and learner.\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nmodel_mlr3 <- mlr3::resample(\n    task = task,\n    learner = learner,\n    resampling = resampling\n)\nlearner$train(task)\n```\n:::\n\n\n\n\n:::\n\n# Evaluation\n\nAfter the models are trained, we want to evaluate their performance.\nHere, we use two of the most common metrics for regression tasks: the root mean square error (RMSE) and the coefficient of determination (R^2^).\n\n::: {.panel-tabset group=\"language\"}\n\n## caret\n\nRMSE and R^2^ are calculated by default in **caret**.\nThe performance metrics are then stored in the `results` object of the model.\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nmodel_caret$results\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n  mtry  splitrule min.node.size     RMSE  Rsquared       MAE    RMSESD\n1    8 extratrees             5 1.119936 0.8406388 0.9008884 0.2269326\n  RsquaredSD     MAESD\n1 0.06159361 0.1399976\n```\n\n\n:::\n:::\n\n\n\n\n## tidymodels\n\nRMSE and R^2^ are calculated by default in **tidymodels**.\nThe performance metrics are extracted from the resampling results using the `collect_metrics()` function.\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ntune::collect_metrics(rf_spatial)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 2 × 6\n  .metric .estimator  mean     n std_err .config             \n  <chr>   <chr>      <dbl> <int>   <dbl> <chr>               \n1 rmse    standard   1.10      5  0.0903 Preprocessor1_Model1\n2 rsq     standard   0.858     5  0.0424 Preprocessor1_Model1\n```\n\n\n:::\n:::\n\n\n\n\n## mlr3\n\nWe need to specify the measures we want to calculate using the `msr()` function.\nThen, the `aggregate()` method is used to calculate the selected performance metrics.\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nmy_measures <- c(mlr3::msr(\"regr.rmse\"), mlr3::msr(\"regr.rsq\"))\nmodel_mlr3$aggregate(measures = my_measures)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nregr.rmse       rsq \n1.1391701 0.8209292 \n```\n\n\n:::\n:::\n\n\n\n\n:::\n\n# Prediction\n\nOur goal is to predict the temperature in Spain using the covariates from the `predictor_stack` dataset.\nThus, we want to obtain a map of the predicted temperature values for the entire country.\nThe `predict()` function of the **terra** package makes model predictions on the new raster data.\n\n::: {.panel-tabset group=\"language\"}\n\n## caret\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\npred_caret <- terra::predict(predictor_stack, model_caret, na.rm = TRUE)\nplot(pred_caret)\n```\n\n::: {.cell-output-display}\n![](index_files/figure-html/index-16-1.png){width=672}\n:::\n:::\n\n\n\n\n## tidymodels\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\npred_tidymodels <- terra::predict(predictor_stack, model_tidymodels, na.rm = TRUE)\nplot(pred_tidymodels)\n```\n\n::: {.cell-output-display}\n![](index_files/figure-html/index-17-1.png){width=672}\n:::\n:::\n\n\n\n\n## mlr3\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\npred_mlr3 <- terra::predict(predictor_stack, learner, na.rm = TRUE)\nplot(pred_mlr3)\n```\n\n::: {.cell-output-display}\n![](index_files/figure-html/index-18-1.png){width=672}\n:::\n:::\n\n\n\n\n:::\n\n# Area of applicability\n\nThe area of applicability (AoA) is a method to assess the what is the area of the input space that is similar to the training data.\nIt is a useful tool to evaluate the model performance and to identify the areas where the model can be applied.\nAreas outside the AoA are considered to be outside the model's applicability domain, and thus, the predictions in these areas should be interpreted with caution or not used at all.\n\n::: {.panel-tabset group=\"language\"}\n\n## caret\n\nThe AoA method's original implementation is in the **CAST** package -- a package that extends the **caret** package.\nThe AoA is calculated using the `aoa()` function, which takes the new data (the covariates) and the model as input.\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nAOA_caret <- CAST::aoa(\n    newdata = predictor_stack,\n    model = model_caret,\n    verbose = FALSE\n)\nplot(AOA_caret$AOA)\n```\n\n::: {.cell-output-display}\n![](index_files/figure-html/index-19-1.png){width=672}\n:::\n:::\n\n\n\n\n## tidymodels\n\nThe **waywiser** package implements the AoA method for **tidymodels**^[It is not a wrapper for the **CAST** package, but a separate implementation with some differences as you may read in the function documentation -- `?ww_area_of_applicability`].\nThe `ww_area_of_applicability()` function takes the training data and variable importance as input.\nThen, to obtain the AoA, we use the `predict()` function from the **terra** package.^[Thus, this approach allow to check the AoA for each new data set, not only the training data.]\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nmodel_aoa <- waywiser::ww_area_of_applicability(\n    st_drop_geometry(temperature_train[, predictor_names]),\n    importance = vip::vi_model(model_tidymodels)\n)\nAOA_tidymodels <- terra::predict(predictor_stack, model_aoa)\nplot(AOA_tidymodels$aoa)\n```\n\n::: {.cell-output-display}\n![](index_files/figure-html/index-20-1.png){width=672}\n:::\n:::\n\n\n\n\n## mlr3\n\nThe **CAST** package can calculate the AoA for **mlr3** models.\nHowever, then we need to specify various arguments, such as a raster with covariates, the training data, the variables to be used, the weights of the variables, and the cross-validation folds.\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nrsmp_cv <- resampling$instantiate(task)\n\nAOA_mlr3 <- CAST::aoa(\n    newdata = predictor_stack,\n    train = as.data.frame(task$data()),\n    variables = task$feature_names,\n    weight = data.frame(t(learner$importance())),\n    CVtest = rsmp_cv$instance[order(row_id)]$fold,\n    verbose = FALSE\n)\nplot(AOA_mlr3$AOA)\n```\n\n::: {.cell-output-display}\n![](index_files/figure-html/index-21-1.png){width=672}\n:::\n:::\n\n\n\n\n:::\n\n# Conclusion\n\nIn this blog post, we compared three of the most popular machine learning frameworks in R: **caret**, **tidymodels**, and **mlr3**.\nWe demonstrated how to use these frameworks for a spatial machine learning task, including model specification, training, evaluation, prediction, and obtaining the area of applicability.\n\nThere is a lot of overlap in functionality between the three frameworks.\nSimultaneously, the frameworks differ in their design philosophy and implementation.\nSome, as **caret**, are more focused on providing a consistent and concise interface, but it offers limited flexibility.\nOthers, like **tidymodels** and **mlr3**, are more modular and flexible, allowing for more complex workflows and customizations, which also makes them more complex to learn and use.\n\nMany additional steps can be added to the presented workflow, such as feature engineering, variable selection, hyperparameter tuning, model interpretation, and more.\nIn the next blog posts, we will show these three frameworks in more detail, and then also present some other packages that can be used for spatial machine learning in R.\n\n# Acknowledgments\n\nThis blog post series is possible due to the financial support of the European Union’s Horizon Europe research and innovation programme under the Marie Skłodowska-Curie grant agreement No. 101147446.\n",
    "supporting": [
      "index_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}